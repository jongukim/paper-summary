{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Empirical Model of Large-Batch Training (2018.12, OpenAI)\n",
    "\n",
    "- [1] [OpenAI Blog](https://blog.openai.com/science-of-ai/): How AI Training Scales\n",
    "- [2] [Paper](https://arxiv.org/pdf/1812.06162.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 적절한 batch size?\n",
    "\n",
    "초기 연구들은 아주 작은 값을 사용했다. 32, 64, 128 정도.\n",
    "\n",
    "최근 연구를 보면 RL 학습 시 수백만 단위까지 batch size가 커지기도 한다고."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배치가 크다는 건?\n",
    "\n",
    "전체 dataset 중 더 많은 부분을 보고 다음 optimizing step을 결정하는 것.\n",
    "\n",
    "더 정답에 가까운 방향을 설정할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그러면 무조건 키우면 좋은 것 아닌가?\n",
    "\n",
    "그만큼 하나의 batch로부터 gradient를 계산하는데 자원이 많이 들어간다.\n",
    "\n",
    "효율적이지 않다.\n",
    "\n",
    "True gradient에 가까워질수록 값의 차이는 별로 없어진다.\n",
    "\n",
    "명심하자. 어차피 점프는 한 번이다.\n",
    "\n",
    "적당한 batch size를 잡으면 학습도 빨리하고 자원은 덜 들일 수 있다.\n",
    "\n",
    "OpenAI에서는 이 '적당한 batch size'를 *critical batch size*라고 표현한다.\n",
    "\n",
    "![](https://blog.openai.com/content/images/2018/12/basic-scaling-1.svg)\n",
    "(figure src: [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 방향을 잘 잡았다 확신이 있다면 크게 점프해도 되지 않나?\n",
    "\n",
    "맞다. 방향을 잘 잡았다면 그곳을 향해 더 많이 뛰어도 된다.\n",
    "\n",
    "즉, batch size가 클 때 learning rate를 더 크게 잡아도 괜찮다는 것이다.\n",
    "\n",
    "![](./Empirical-figure2.png)\n",
    "(figure src: [2])\n",
    "\n",
    "그런데, 얼마나 많이 뛸 건가? minina를 건너뛸 수도 있잖아.\n",
    "\n",
    "Learning rate는 어려운 파라미터다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  배치를 키우면 training loss는 좋아도 test loss가 별로다(즉, generalization이 잘 안된다는) 연구가 있었단다.\n",
    "\n",
    "그에 대한 반박 연구도 있었다.\n",
    "\n",
    "OpenAI도 말이 안된다고 보고 있다.\n",
    "\n",
    "나도 마찬가지."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise\n",
    "\n",
    "OpenAI는 noise라는 개념을 정의한다.\n",
    "\n",
    "이상적인 grad($G_{true}$라고 표현)가 있을 때 내가 계산한 grad가 얼마나 틀렸는지를 말하는 듯.\n",
    "\n",
    "모델이 크면 노이즈가 많은 것이 일반적.\n",
    "\n",
    "학습해야 할 파라미터가 많으니 정확한 gradient를 찾기가 힘들어질 것.\n",
    "\n",
    "![](https://blog.openai.com/content/images/2018/12/noise-summary-3.svg)\n",
    "(figure src: [1])\n",
    "\n",
    "노이즈가 별로 없으면? 지금 충분히 큰 배치를 사용하고 있다는 것.\n",
    "\n",
    "노이즈가 많으면? 더 큰 배치를 써도 된다는 것.\n",
    "\n",
    "더 복잡한 모델 -> 더 많은 노이즈 -> 더 큰 batch size 써도 됨\n",
    "\n",
    "즉, 복잡한 문제일수록 data-parallel을 써서 더 큰 batch를 사용하면 효과를 본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기타 언급\n",
    "\n",
    "#### 각 샘플의 특성이 강하면 배치를 작게 잡고, 전반적으로 유사하면 크게 잡는 것이 좋다?\n",
    "\n",
    "합리적인 이야기인가? 결국 전체 데이터셋을 보고 학습하게 되는 것 아닌가?\n",
    "\n",
    "#### 학습이 진행될수록 노이즈 스케일이 커지더라.\n",
    "\n",
    "Minima로 갈수록 정확한 방향을 (오히려) 찾기 힘들어진다는 의미? \n",
    "\n",
    "또는 (OpenAI에 설명에 따르면) 딥러닝이 학습 초반에는 확실한 feature에 대해 학습을 시작하다가, 점차 복잡한 부분에 대해 공부하기 때문이란다. 뒤로 갈수록 더 어려워져서 틀린다는 것. 그런가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 혼자 생각\n",
    "\n",
    "#### 구현 시, 학습 도중에 batch size를 바꾸는 것은 손해일까?\n",
    "\n",
    "DataLoader는 배치에 맞게 memory에 미리 올려두는 것일까, 아니면 그때그때 올리는 것일까?\n",
    "\n",
    "보통 성능을 위해 **pin_memory=True** 를 준다. 아마도 성능상 손해를 볼 듯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
